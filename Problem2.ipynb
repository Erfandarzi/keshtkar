{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Erfandarzi/keshtkar/blob/master/Problem2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xitplqMNk_Hc",
        "outputId": "ed4f60d2-878d-4056-c438-352dac39a112",
        "colab": {
          "height": 420
        }
      },
      "source": [
        "#@title Introducing Colaboratory { display-mode: \"form\" }\n",
        "#@markdown This 3-minute video gives an overview of the key features of Colaboratory:\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('inN8seMm7UI', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"600\"\n",
              "            height=\"400\"\n",
              "            src=\"https://www.youtube.com/embed/inN8seMm7UI\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f956e9dda50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJBs_flRovLc"
      },
      "source": [
        "## Getting Started\n",
        "\n",
        "The document you are reading is a  [Jupyter notebook](https://jupyter.org/), hosted in Colaboratory. It is not a static page, but an interactive environment that lets you write and execute code in Python and other languages.\n",
        "\n",
        "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJr_9dXGpJ05",
        "outputId": "5626194c-e802-4293-942d-2908885c3c1f",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "seconds_in_a_day"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\".\n",
        "\n",
        "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE-Ez1qtyIA",
        "outputId": "8d2e4259-4682-4e19-b683-7b9087f28820",
        "colab": {
          "height": 35
        }
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "seconds_in_a_week"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lSrWNr3MuFUS"
      },
      "source": [
        "For more information about working with Colaboratory notebooks, see [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Rh3-Vt9Nev9"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "Learn how to make the most of Python, Jupyter, Colaboratory, and related tools with these resources:\n",
        "\n",
        "### Working with Notebooks in Colaboratory\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n",
        " [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)\n",
        "\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas](/notebooks/mlcc/intro_to_pandas.ipynb)\n",
        "- [Tensorflow concepts](/notebooks/mlcc/tensorflow_programming_concepts.ipynb)\n",
        "- [First steps with TensorFlow](/notebooks/mlcc/first_steps_with_tensor_flow.ipynb)\n",
        "- [Intro to neural nets](/notebooks/mlcc/intro_to_neural_nets.ipynb)\n",
        "- [Intro to sparse data and embeddings](/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb)\n",
        "\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "## Machine Learning Examples: Seedbank\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out the [Seedbank](https://research.google.com/seedbank/) project.\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Neural Style Transfer](https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras): Use deep learning to transfer style between images.\n",
        "- [EZ NSynth](https://research.google.com/seedbank/seed/ez_nsynth): Synthesize audio with WaveNet auto-encoders.\n",
        "- [Fashion MNIST with Keras and TPUs](https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus): Classify fashion-related images with deep learning.\n",
        "- [DeepDream](https://research.google.com/seedbank/seed/deepdream): Produce DeepDream images from your own photos.\n",
        "- [Convolutional VAE](https://research.google.com/seedbank/seed/convolutional_vae): Create a generative model of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F86If7wEx4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45095c2d-5d3d-4770-94d1-01fb4d76e959"
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n",
        "print('hello')\n",
        "batch_size = 32\n",
        "nb_classes = 10\n",
        "nb_epoch = 30\n",
        "lr=0.001\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_val = X_train[40000:].reshape(20000, 784)\n",
        "X_train = X_train[:40000].reshape(40000, 784)\n",
        "# X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_val /= 255\n",
        "\n",
        "Y_val = np_utils.to_categorical(y_train, nb_classes)[40000:]\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)[:40000]\n",
        "# Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# Deep Multilayer Perceptron model\n",
        "model = Sequential()\n",
        "model.add(Dense(output_dim=512, input_dim=784, init='normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(output_dim=512, input_dim=512, init='normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(output_dim=512, input_dim=512, init='normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(output_dim=10, input_dim=512, init='normal'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train, Y_train,nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = 'history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "files.download(' lr='+str(lr)+'batch='+str(batch_size)+'.csv') \n",
        "  \n",
        "# Evaluate\n",
        "evaluation = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, units=512, kernel_initializer=\"normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=512, units=512, kernel_initializer=\"normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=512, units=512, kernel_initializer=\"normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=512, units=10, kernel_initializer=\"normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_76 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "activation_76 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_77 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_78 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_79 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 932,362\n",
            "Trainable params: 932,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 9s 214us/step - loss: 0.2444 - acc: 0.9283\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 8s 191us/step - loss: 0.1330 - acc: 0.9669\n",
            "Epoch 3/30\n",
            " 6976/40000 [====>.........................] - ETA: 6s - loss: 0.0963 - acc: 0.9752"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-17e38f060044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# convert the history.history dict to a pandas DataFrame:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z34HNboXNR6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJRfabXmKWBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "82460542-9917-4579-f2d0-c2889b204df3"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Hyper parameters\n",
        "batch_size = 128\n",
        "nb_epoch = 30\n",
        "\n",
        "# Parameters for MNIST dataset\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5BZezPuNW60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "67dde0d0-6cd4-4329-b176-39c4102c5800"
      },
      "source": [
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw0pdEUrUymA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c75306d-17ff-48f9-efd2-2305334187fe"
      },
      "source": [
        "encoding_dim = 32\n",
        "\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)  # Multiple encoding\n",
        "decoded = Dense(64, activation='relu')(encoded)  # and decoding layers.\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "\n",
        "autoencoder = Model(input=input_img, output=decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "autoencoder.summary()\n",
        "\n",
        "\n",
        "encoder = Model(autoencoder.input, autoencoder.layers[-4].output)\n",
        "encoder.summary()\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 784)               101136    \n",
            "=================================================================\n",
            "Total params: 222,384\n",
            "Trainable params: 222,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "=================================================================\n",
            "Total params: 110,816\n",
            "Trainable params: 110,816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9sYMP8RNgev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68029ae7-cb06-4497-b6ea-ce28cae85323"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                nb_epoch=nb_epoch, batch_size=batch_size, shuffle=True, verbose=1,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.2978 - val_loss: 0.2525\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.2388 - val_loss: 0.2186\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.2065 - val_loss: 0.1917\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1871 - val_loss: 0.1777\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1742 - val_loss: 0.1671\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1648 - val_loss: 0.1593\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1581 - val_loss: 0.1543\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1524 - val_loss: 0.1480\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1482 - val_loss: 0.1442\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1448 - val_loss: 0.1410\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1419 - val_loss: 0.1393\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1394 - val_loss: 0.1364\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1369 - val_loss: 0.1352\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1346 - val_loss: 0.1318\n",
            "Epoch 15/30\n",
            "18560/60000 [========>.....................] - ETA: 2s - loss: 0.1331"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-972f22da1bf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m autoencoder.fit(x_train, x_train,\n\u001b[1;32m      2\u001b[0m                 \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 validation_data=(x_test, x_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    192\u001b[0m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[1;32m    193\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmnYR5THRV-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "461f79ae-cb38-4153-d9a4-e877cb4b9af1"
      },
      "source": [
        "encoderdecoder=autoencoder.predict(x_train)\n",
        "encoded=encoder.predict(x_train)\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(np.reshape(x_train[300],(28,28)))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(np.reshape(encoderdecoder[300],(28,28)))\n",
        "plt.show()\n",
        "print((encoded))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB5Ig7EAShB1IgrADSfw/FJ0Y5wS3U5MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEoQdSIKwA0kQdiCJ/wfzLcnc99Dz3QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[11.053128   6.6165695  6.8909736 ...  0.         5.515209   0.       ]\n",
            " [ 6.7437205 11.352778  10.010343  ...  0.         3.9720864  0.       ]\n",
            " [ 5.2276654  0.         2.5341744 ...  0.         6.1068907  0.       ]\n",
            " ...\n",
            " [ 7.855392   8.876904   1.6544573 ...  0.         6.7352166  0.       ]\n",
            " [ 5.1950393  7.796343   4.348105  ...  0.         5.024893   0.       ]\n",
            " [ 9.784242  10.705008   4.589142  ...  0.         7.740166   0.       ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCuUefJcPyQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "718193e5-7f16-435d-8947-fcde4cb9c1a5"
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n",
        "batch_size = 4\n",
        "nb_classes = 10\n",
        "nb_epoch = 30\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "# Deep Multilayer Perceptron model\n",
        "model = Sequential()\n",
        "model.add(Dense(output_dim=625, input_dim=32, init='normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(output_dim=625, input_dim=625, init='normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(output_dim=10, input_dim=625, init='normal'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001, rho=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train\n",
        "history = model.fit(encoded, Y_train, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=32, units=625, kernel_initializer=\"normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=625, units=625, kernel_initializer=\"normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=625, units=10, kernel_initializer=\"normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 625)               20625     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 625)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 625)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 625)               391250    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 625)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 625)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                6260      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 418,135\n",
            "Trainable params: 418,135\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.7217 - acc: 0.8403\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.9160 - acc: 0.8523\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 1.0345 - acc: 0.8526\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 1.1330 - acc: 0.8559\n",
            "Epoch 5/30\n",
            " 8000/60000 [===>..........................] - ETA: 1:07 - loss: 1.1349 - acc: 0.8486"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}